{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import csv\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "imdb = keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = keras.datasets.imdb\n",
    "word_index = imdb.get_word_index()\n",
    "word_index = {k:(v+3) for k,v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "label=[]\n",
    "tweet=[]\n",
    "tsvfile = open('Apple-Twitter-Sentiment-DFE.csv')\n",
    "reader = csv.reader(tsvfile, delimiter=',')\n",
    "for row in reader:\n",
    "        #print(type(row[5]))\n",
    "        r=[]\n",
    "        l=[]\n",
    "        if row[5]!='3' :\n",
    "                for i in (row[11].split()):\n",
    "                    try:\n",
    "                        r.append(word_index[i])\n",
    "                    except KeyError:\n",
    "                        r.append(word_index[\"<UNK>\"])\n",
    "                if row[5]=='5':\n",
    "                    label.append(1)\n",
    "                elif row[5]=='1':\n",
    "                    label.append(0)\n",
    "                if row[5]!='not_relevant':\n",
    "                    data.append(r)\n",
    "                    tweet.append(row[11])\n",
    "del data[0]\n",
    "traindata=np.array(data[:1400])\n",
    "valdata=np.array(data[1400:1642])\n",
    "del data\n",
    "trainlabel=np.array(label[:1400])\n",
    "vallabel=np.array(label[1400:1642])\n",
    "del label\n",
    "valtweet=tweet[1400:1642]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = keras.preprocessing.sequence.pad_sequences(traindata,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=40)\n",
    "\n",
    "valdata = keras.preprocessing.sequence.pad_sequences(valdata,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anoth\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 32)            3200000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,201,089\n",
      "Trainable params: 3,201,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 100000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size,32,input_length=40))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anoth\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.6720 - acc: 0.7279\n",
      "Epoch 2/40\n",
      "1400/1400 [==============================] - 1s 1ms/sample - loss: 0.6318 - acc: 0.7529\n",
      "Epoch 3/40\n",
      "1400/1400 [==============================] - 1s 1ms/sample - loss: 0.5964 - acc: 0.7529\n",
      "Epoch 4/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.5707 - acc: 0.7529\n",
      "Epoch 5/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.5589 - acc: 0.7529\n",
      "Epoch 6/40\n",
      "1400/1400 [==============================] - 1s 1ms/sample - loss: 0.5535 - acc: 0.7529\n",
      "Epoch 7/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.5491 - acc: 0.7529\n",
      "Epoch 8/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.5437 - acc: 0.7529\n",
      "Epoch 9/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.5378 - acc: 0.7529\n",
      "Epoch 10/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.5310 - acc: 0.7529\n",
      "Epoch 11/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.5219 - acc: 0.7529\n",
      "Epoch 12/40\n",
      "1400/1400 [==============================] - 1s 1ms/sample - loss: 0.5104 - acc: 0.7529\n",
      "Epoch 13/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.4960 - acc: 0.7529\n",
      "Epoch 14/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.4788 - acc: 0.7529\n",
      "Epoch 15/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.4597 - acc: 0.7536\n",
      "Epoch 16/40\n",
      "1400/1400 [==============================] - 1s 991us/sample - loss: 0.4394 - acc: 0.7550\n",
      "Epoch 17/40\n",
      "1400/1400 [==============================] - 1s 988us/sample - loss: 0.4157 - acc: 0.7736\n",
      "Epoch 18/40\n",
      "1400/1400 [==============================] - 1s 1ms/sample - loss: 0.3937 - acc: 0.8014\n",
      "Epoch 19/40\n",
      "1400/1400 [==============================] - 1s 1ms/sample - loss: 0.3725 - acc: 0.8257\n",
      "Epoch 20/40\n",
      "1400/1400 [==============================] - 1s 1ms/sample - loss: 0.3532 - acc: 0.8271\n",
      "Epoch 21/40\n",
      "1400/1400 [==============================] - 1s 961us/sample - loss: 0.3353 - acc: 0.8586\n",
      "Epoch 22/40\n",
      "1400/1400 [==============================] - 1s 963us/sample - loss: 0.3172 - acc: 0.8479\n",
      "Epoch 23/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.2987 - acc: 0.8893\n",
      "Epoch 24/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.2828 - acc: 0.8843\n",
      "Epoch 25/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.2668 - acc: 0.8943\n",
      "Epoch 26/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.2530 - acc: 0.9121\n",
      "Epoch 27/40\n",
      "1400/1400 [==============================] - 1s 1ms/sample - loss: 0.2388 - acc: 0.9029\n",
      "Epoch 28/40\n",
      "1400/1400 [==============================] - 1s 1ms/sample - loss: 0.2281 - acc: 0.9300\n",
      "Epoch 29/40\n",
      "1400/1400 [==============================] - 1s 1ms/sample - loss: 0.2162 - acc: 0.9207\n",
      "Epoch 30/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.2034 - acc: 0.9286\n",
      "Epoch 31/40\n",
      "1400/1400 [==============================] - 3s 2ms/sample - loss: 0.1940 - acc: 0.9436\n",
      "Epoch 32/40\n",
      "1400/1400 [==============================] - 2s 2ms/sample - loss: 0.1866 - acc: 0.9321\n",
      "Epoch 33/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.1764 - acc: 0.9421\n",
      "Epoch 34/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.1694 - acc: 0.9479\n",
      "Epoch 35/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.1623 - acc: 0.9429\n",
      "Epoch 36/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.1548 - acc: 0.9514\n",
      "Epoch 37/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.1500 - acc: 0.9457\n",
      "Epoch 38/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.1489 - acc: 0.9471\n",
      "Epoch 39/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.1406 - acc: 0.9607\n",
      "Epoch 40/40\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.1373 - acc: 0.9564\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(traindata,\n",
    "                    trainlabel,\n",
    "                    epochs=40,\n",
    "                    batch_size=100,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 644us/sample - loss: 0.8015 - acc: 0.6942\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(valdata, vallabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=model.predict(valdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(vallabel[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in s:\n",
    "    if i>=0.5:\n",
    "        t.append(1)\n",
    "    else:\n",
    "        t.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file =open('PredictionsSingle.csv', mode='w')\n",
    "fieldnames = ['Tweet', 'Actual', 'Predicted']\n",
    "writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "writer.writeheader()\n",
    "for i in range(0,len(s)):\n",
    "       writer.writerow({'Tweet': valtweet[i], 'Actual': vallabel[i], 'Predicted':t[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
